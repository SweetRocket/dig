{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_func(func, *args, **kwargs):\n",
    "    try:\n",
    "        return func(*args, **kwargs)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmapy\n",
    "cmap = cmapy.cmap('nipy_spectral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromONNX('../models/handmotion/best.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\"Both_long\", \"One\", \"Both_short\", \"NONE\"]\n",
    "colors = np.random.uniform(0, 255, size=(len(CLASSES), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_box(img, class_id, confidence, x, y, x_plus_w, y_plus_h):\n",
    "    label = f'{CLASSES[class_id]} ({confidence:.2f})'\n",
    "    color = colors[class_id]\n",
    "    cv2.rectangle(img, (x, y), (x_plus_w, y_plus_h), color, 2)\n",
    "    cv2.putText(img, label, (x - 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 66\u001b[0m\n\u001b[0;32m     62\u001b[0m index \u001b[39m=\u001b[39m result_boxes[i]\n\u001b[0;32m     63\u001b[0m box \u001b[39m=\u001b[39m boxes[index]\n\u001b[0;32m     64\u001b[0m detection \u001b[39m=\u001b[39m {\n\u001b[0;32m     65\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mclass_id\u001b[39m\u001b[39m'\u001b[39m: class_ids[index],\n\u001b[1;32m---> 66\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mclass_name\u001b[39m\u001b[39m'\u001b[39m: CLASSES[class_ids[index]],\n\u001b[0;32m     67\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mconfidence\u001b[39m\u001b[39m'\u001b[39m: scores[index],\n\u001b[0;32m     68\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mbox\u001b[39m\u001b[39m'\u001b[39m: box,\n\u001b[0;32m     69\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mscale\u001b[39m\u001b[39m'\u001b[39m: scale}\n\u001b[0;32m     70\u001b[0m detections\u001b[39m.\u001b[39mappend(detection)\n\u001b[0;32m     71\u001b[0m draw_bounding_box(box_img, class_ids[index], scores[index], \u001b[39mround\u001b[39m(box[\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m scale), \u001b[39mround\u001b[39m(box[\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m scale),\n\u001b[0;32m     72\u001b[0m                   \u001b[39mround\u001b[39m((box[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m box[\u001b[39m2\u001b[39m]) \u001b[39m*\u001b[39m scale), \u001b[39mround\u001b[39m((box[\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m box[\u001b[39m3\u001b[39m]) \u001b[39m*\u001b[39m scale))\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) # 프레임 수 구하기\n",
    "delay = int(1000/fps)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "history = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "# 배경 제거 객체\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    \n",
    "    # 배경 제거 마스크 계산\n",
    "    fgmask = fgbg.apply(frame)\n",
    "    \n",
    "    # make 24 frame of history based on fgmask\n",
    "    history = np.where(fgmask == 255, 250, history)\n",
    "    history = np.where(history > 0, history - 10, history)\n",
    "    \n",
    "    # make clip for safety\n",
    "    history = np.clip(history, 0, 255)\n",
    "    \n",
    "    # color map\n",
    "    color_map_history = cv2.applyColorMap(history, cmap)\n",
    "    \n",
    "    box_img = color_map_history.copy()\n",
    "    \n",
    "    # detect\n",
    "    length = max((height, width))\n",
    "    scale = length / 640\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(box_img, scalefactor=1 / 255, size=(640, 640))\n",
    "    net.setInput(blob)\n",
    "    outputs = net.forward()\n",
    "    \n",
    "    outputs = np.array([cv2.transpose(outputs[0])])\n",
    "    rows = outputs.shape[1]\n",
    "    \n",
    "    boxes = []\n",
    "    scores = []\n",
    "    class_ids = []\n",
    "    for i in range(rows):\n",
    "        classes_scores = outputs[0][i][4:]\n",
    "        (minScore, maxScore, minClassLoc, (x, maxClassIndex)) = cv2.minMaxLoc(classes_scores)\n",
    "        if maxScore >= 0.25:\n",
    "            box = [\n",
    "                outputs[0][i][0] - (0.5 * outputs[0][i][2]), outputs[0][i][1] - (0.5 * outputs[0][i][3]),\n",
    "                outputs[0][i][2], outputs[0][i][3]]\n",
    "            boxes.append(box)\n",
    "            scores.append(maxScore)\n",
    "            class_ids.append(maxClassIndex)\n",
    "\n",
    "    result_boxes = cv2.dnn.NMSBoxes(boxes, scores, 0.25, 0.45, 0.5)\n",
    "    \n",
    "    detections = []\n",
    "    for i in range(len(result_boxes)):\n",
    "        index = result_boxes[i]\n",
    "        box = boxes[index]\n",
    "        detection = {\n",
    "            'class_id': class_ids[index],\n",
    "            'class_name': CLASSES[class_ids[index]],\n",
    "            'confidence': scores[index],\n",
    "            'box': box,\n",
    "            'scale': scale}\n",
    "        detections.append(detection)\n",
    "        draw_bounding_box(box_img, class_ids[index], scores[index], round(box[0] * scale), round(box[1] * scale),\n",
    "                          round((box[0] + box[2]) * scale), round((box[1] + box[3]) * scale))\n",
    "\n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('bgsub',fgmask)\n",
    "    cv2.imshow('history', history)\n",
    "    cv2.imshow('cmaped', color_map_history)\n",
    "    cv2.imshow('box', box_img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xff == 27:\n",
    "        break\n",
    "\n",
    "try_func(cap.release)\n",
    "try_func(cv2.destroyAllWindows)\n",
    "\n",
    "\n",
    "print(\"Goodbye User\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_func(cap.release)\n",
    "try_func(cv2.destroyAllWindows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
